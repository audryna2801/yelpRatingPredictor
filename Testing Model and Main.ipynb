{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhedintzaaudryna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import itertools\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from analyze_words import get_df_idf_stops\n",
    "\n",
    "\n",
    "def evaluateModel(prediction, y_test):\n",
    "    '''\n",
    "    Calculate the accuracy of a model based on the proportion of\n",
    "    accurate predictions using the testing data. Accuracy is\n",
    "    weighted by the deviance from the actual rating.\n",
    "\n",
    "    Inputs:\n",
    "      - prediction (arr): predicted y values\n",
    "      - y_test (arr): actual y values\n",
    "\n",
    "    Returns: float\n",
    "    '''\n",
    "    # Convert into DataFrame for easier handling\n",
    "    pred_test_df = pd.DataFrame({\"predict\": prediction,\n",
    "                                 \"actual\": y_test}).astype(\"int\")\n",
    "    pred_test_df[\"difference\"] = (pred_test_df.predict\n",
    "                                  - pred_test_df.actual).abs()\n",
    "\n",
    "    num_tests = len(pred_test_df)\n",
    "    total_deviance = pred_test_df[\"difference\"].sum()\n",
    "\n",
    "    # Maximum deviance is 4 (5-star rating vs. 1-star rating)\n",
    "    weighted_accuracy = 1 - (total_deviance / (4 * num_tests))\n",
    "\n",
    "    return weighted_accuracy\n",
    "\n",
    "\n",
    "def get_weighted_accuracy(x_train, x_test, y_train, y_test, alpha):\n",
    "    '''\n",
    "    Calculate weighted accuracy of a model.\n",
    "\n",
    "    Inputs:\n",
    "      - x_train (DataFrame): x training data\n",
    "      - x_test (DataFrame): x testing data\n",
    "      - y_train (arr): y training data\n",
    "      - y_test (arr): y testing data\n",
    "      - alpha (float): constant that multiplies regularization term\n",
    "\n",
    "    Returns: float\n",
    "    '''\n",
    "    model = linear_model.SGDClassifier(alpha=alpha)\n",
    "    trained_model = model.fit(x_train, y_train)\n",
    "    prediction = trained_model.predict(x_test)\n",
    "    weighted_accuracy = evaluateModel(prediction, y_test)\n",
    "\n",
    "    return weighted_accuracy\n",
    "\n",
    "\n",
    "def feature_selection(model, x_train, y_train, x_test):\n",
    "    '''\n",
    "    Performs feature selection to minimize overfitting\n",
    "\n",
    "    Inputs:\n",
    "        - model (Model): model being applied\n",
    "        - x_train (DataFrame): x training data\n",
    "        - y_train (arr): y training data\n",
    "        - x_test (DataFrame): x testing data\n",
    "\n",
    "    Returns: 2 arrs (filtered x_train, filtered x_test), feature selector obj\n",
    "    '''\n",
    "    trained_model = model.fit(x_train, y_train)\n",
    "    feature_selection_model = SelectFromModel(trained_model)\n",
    "    trained_feature_selection_model = feature_selection_model.fit(x_train,\n",
    "                                                                  y_train)\n",
    "    x_train = trained_feature_selection_model.transform(x_train)\n",
    "    x_test = trained_feature_selection_model.transform(x_test)\n",
    "\n",
    "    return x_train, x_test, trained_feature_selection_model\n",
    "\n",
    "\n",
    "def optimize_model(csv_file, testing_fraction):\n",
    "    '''\n",
    "    Find the optimal combination of parameters (maximum n-gram length,\n",
    "    whether to lemmatize, number of stop words, and alpha) for the\n",
    "    suggested star rating model, as well as the corresponding DataFrame, \n",
    "    idf dictionary, and list of stop words.\n",
    "\n",
    "    Inputs:\n",
    "      - csv_file (string): CSV file name\n",
    "      - testing_fraction (float): proportion of data reserved for testing\n",
    "\n",
    "    Returns: DataFrame, dict (parameters), dict (idf), list of str\n",
    "    '''\n",
    "    # Combinations\n",
    "    ngrams = [1, 2, 3]\n",
    "    num_stop_words = [0, 10, 20]\n",
    "    alphas = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "    all_combi = list(itertools.product(ngrams, num_stop_words, alphas))\n",
    "\n",
    "    max_accuracy = -1\n",
    "    best_df = None\n",
    "    best_alpha = None\n",
    "    best_vectorizer = None\n",
    "\n",
    "    print(\"Completed initializing.\")\n",
    "\n",
    "    for combi in all_combi:\n",
    "        ngram, num_stop_words, alpha = combi\n",
    "        X, y_values, vectorizer = get_df_idf_stops(csv_file, n=ngram,\n",
    "                                                   num_stop_words=num_stop_words)\n",
    "        x_train, x_test, y_train, y_test = \\\n",
    "            train_test_split(X, y_values,\n",
    "                             test_size=testing_fraction, random_state=33)\n",
    "        weighted_accuracy = get_weighted_accuracy(x_train, x_test,\n",
    "                                                  y_train, y_test, alpha)\n",
    "\n",
    "        print(combi, \"Finished testing. | Accuracy: \", weighted_accuracy)\n",
    "\n",
    "        if weighted_accuracy > max_accuracy:\n",
    "            max_accuracy = weighted_accuracy\n",
    "            best_x = X\n",
    "            best_y = y_values\n",
    "            best_alpha = alpha\n",
    "            best_vectorizer = vectorizer\n",
    "\n",
    "    return best_x, best_y, best_alpha, best_vectorizer\n",
    "\n",
    "\n",
    "def main_modelling(csv_file='smaller_dataset.csv', testing_fraction=0.2):\n",
    "    '''\n",
    "    Generate the optimal model for predicting Yelp review ratings by\n",
    "    cycling through combinations of parameters and save it as a PKL file.\n",
    "    Also saves other parameters for user input processing in JSON. \n",
    "\n",
    "    Inputs:\n",
    "      - csv_file (string): CSV file name\n",
    "      - testing_fraction (float): proportion of data reserved for testing\n",
    "\n",
    "    Returns: None, writes PKL and JSON files\n",
    "    '''\n",
    "    # Input and Model Tuning\n",
    "    X, y_values, alpha, vectorizer = optimize_model(csv_file,\n",
    "                                                    testing_fraction)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(X, y_values,\n",
    "                         test_size=testing_fraction, random_state=33)\n",
    "\n",
    "    # Feature Selection\n",
    "    model = linear_model.SGDClassifier(alpha=alpha)\n",
    "    x_train, x_test, feature_selector = feature_selection(model, x_train,\n",
    "                                                          y_train, x_test)\n",
    "    final_model = model.fit(x_train, y_train)\n",
    "    prediction = final_model.predict(x_test)\n",
    "\n",
    "    print(\"Final Model Classification Report\")\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(\"Accuracy Score\")\n",
    "    print(evaluateModel(prediction, y_test))\n",
    "\n",
    "    # Save best Model, Vectorizer, and Selector\n",
    "    joblib.dump(final_model, \"new_optimal_args/final_model.pkl\")\n",
    "    joblib.dump(vectorizer, 'new_optimal_args/vectorizer.pkl')\n",
    "    joblib.dump(feature_selector, 'new_optimal_args/selector.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "num_stop_words = 10\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 541 ms, total: 23.5 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y_values, vectorizer = get_df_idf_stops('smaller_dataset.csv', n, num_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.62      0.36        42\n",
      "           2       0.02      0.40      0.04         5\n",
      "           3       0.05      0.33      0.09        40\n",
      "           4       0.40      0.56      0.47       556\n",
      "           5       0.90      0.52      0.65      1357\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.33      0.48      0.32      2000\n",
      "weighted avg       0.73      0.53      0.58      2000\n",
      "\n",
      "Accuracy Score\n",
      "0.82775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new_optimal_args/selector.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(X, y_values,\n",
    "                         test_size=testing_fraction, random_state=33)\n",
    "\n",
    "# Feature Selection\n",
    "model = linear_model.SGDClassifier(alpha=alpha)\n",
    "x_train, x_test, feature_selector = feature_selection(model, x_train,\n",
    "                                                      y_train, x_test)\n",
    "final_model = model.fit(x_train, y_train)\n",
    "prediction = final_model.predict(x_test)\n",
    "\n",
    "print(\"Final Model Classification Report\")\n",
    "print(classification_report(prediction, y_test))\n",
    "print(\"Accuracy Score\")\n",
    "print(evaluateModel(prediction, y_test))\n",
    "\n",
    "# Save best Model, Vectorizer, and Selector\n",
    "joblib.dump(final_model, \"new_optimal_args/final_model.pkl\")\n",
    "joblib.dump(vectorizer, 'new_optimal_args/vectorizer.pkl')\n",
    "joblib.dump(feature_selector, 'new_optimal_args/selector.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed initializing.\n",
      "(1, 0, 0.0001) Finished testing. | Accuracy:  0.87225\n",
      "(1, 0, 0.001) Finished testing. | Accuracy:  0.845125\n",
      "(1, 0, 0.01) Finished testing. | Accuracy:  0.812\n",
      "(1, 0, 0.1) Finished testing. | Accuracy:  0.8166249999999999\n",
      "(1, 0, 1) Finished testing. | Accuracy:  0.762\n",
      "(1, 10, 0.0001) Finished testing. | Accuracy:  0.87225\n",
      "(1, 10, 0.001) Finished testing. | Accuracy:  0.845625\n",
      "(1, 10, 0.01) Finished testing. | Accuracy:  0.81575\n",
      "(1, 10, 0.1) Finished testing. | Accuracy:  0.841125\n",
      "(1, 10, 1) Finished testing. | Accuracy:  0.753875\n",
      "(1, 20, 0.0001) Finished testing. | Accuracy:  0.87175\n",
      "(1, 20, 0.001) Finished testing. | Accuracy:  0.847\n",
      "(1, 20, 0.01) Finished testing. | Accuracy:  0.8215\n",
      "(1, 20, 0.1) Finished testing. | Accuracy:  0.75425\n",
      "(1, 20, 1) Finished testing. | Accuracy:  0.809125\n",
      "(2, 0, 0.0001) Finished testing. | Accuracy:  0.875875\n",
      "(2, 0, 0.001) Finished testing. | Accuracy:  0.83475\n",
      "(2, 0, 0.01) Finished testing. | Accuracy:  0.805625\n",
      "(2, 0, 0.1) Finished testing. | Accuracy:  0.75825\n",
      "(2, 0, 1) Finished testing. | Accuracy:  0.753875\n",
      "(2, 10, 0.0001) Finished testing. | Accuracy:  0.8708750000000001\n",
      "(2, 10, 0.001) Finished testing. | Accuracy:  0.8405\n",
      "(2, 10, 0.01) Finished testing. | Accuracy:  0.8240000000000001\n",
      "(2, 10, 0.1) Finished testing. | Accuracy:  0.809125\n",
      "(2, 10, 1) Finished testing. | Accuracy:  0.83925\n",
      "(2, 20, 0.0001) Finished testing. | Accuracy:  0.871625\n",
      "(2, 20, 0.001) Finished testing. | Accuracy:  0.84325\n",
      "(2, 20, 0.01) Finished testing. | Accuracy:  0.839375\n",
      "(2, 20, 0.1) Finished testing. | Accuracy:  0.840125\n",
      "(2, 20, 1) Finished testing. | Accuracy:  0.809125\n",
      "(3, 0, 0.0001) Finished testing. | Accuracy:  0.867375\n",
      "(3, 0, 0.001) Finished testing. | Accuracy:  0.840625\n",
      "(3, 0, 0.01) Finished testing. | Accuracy:  0.8205\n",
      "(3, 0, 0.1) Finished testing. | Accuracy:  0.753875\n",
      "(3, 0, 1) Finished testing. | Accuracy:  0.809125\n",
      "(3, 10, 0.0001) Finished testing. | Accuracy:  0.865125\n",
      "(3, 10, 0.001) Finished testing. | Accuracy:  0.8362499999999999\n",
      "(3, 10, 0.01) Finished testing. | Accuracy:  0.830125\n",
      "(3, 10, 0.1) Finished testing. | Accuracy:  0.809125\n",
      "(3, 10, 1) Finished testing. | Accuracy:  0.753875\n",
      "(3, 20, 0.0001) Finished testing. | Accuracy:  0.864375\n",
      "(3, 20, 0.001) Finished testing. | Accuracy:  0.840625\n",
      "(3, 20, 0.01) Finished testing. | Accuracy:  0.834625\n",
      "(3, 20, 0.1) Finished testing. | Accuracy:  0.754\n",
      "(3, 20, 1) Finished testing. | Accuracy:  0.809125\n",
      "Final Model Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.71      0.62        79\n",
      "           2       0.07      0.44      0.12        16\n",
      "           3       0.22      0.49      0.30       111\n",
      "           4       0.65      0.58      0.61       866\n",
      "           5       0.77      0.65      0.70       928\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.45      0.57      0.47      2000\n",
      "weighted avg       0.67      0.61      0.63      2000\n",
      "\n",
      "Accuracy Score\n",
      "0.875875\n"
     ]
    }
   ],
   "source": [
    "main_modelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def user_interface():\n",
    "    '''Prompt user to input a review, and suggest a star rating.'''\n",
    "    print(\"==================================================\")\n",
    "    print(\"   Welcome to the Suggested Star Rating System!\")\n",
    "    print()\n",
    "    print(\"            Copy and paste your review.\")\n",
    "    print()\n",
    "    print(\"       Type Control-D to exit the program.\")\n",
    "    print(\"==================================================\")\n",
    "    print()\n",
    "    try:\n",
    "        while True:\n",
    "            review = input(\"Enter review here: \")\n",
    "            review = str(review)\n",
    "            if len(review) >= 50:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please input a longer review.\")\n",
    "\n",
    "        x_array = process_input(review)\n",
    "\n",
    "        final_model = joblib.load(\"new_optimal_args/final_model.pkl\")\n",
    "        prediction = final_model.predict(x_array)\n",
    "        star_rating = int(prediction)\n",
    "\n",
    "        print(\"Your suggested star rating is: {}\".format(star_rating))\n",
    "        print(\"Thank you for using our Suggested Star Rating System!\")\n",
    "    except EOFError:\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "def process_input(review):\n",
    "    '''\n",
    "    Convert a review input by the user into an array of zeros,\n",
    "    where each item corresponding to a valid n-gram in the input\n",
    "    is replaced by the n-gram's tfidf. This allows a review to be\n",
    "    evaluated by a model.\n",
    "\n",
    "    Inputs:\n",
    "      - review (str): review input by user\n",
    "\n",
    "    Returns: arr\n",
    "    '''\n",
    "    vectorizer = joblib.load(\"new_optimal_args/vectorizer.pkl\")\n",
    "    selector = joblib.load(\"new_optimal_args/selector.pkl\")\n",
    "\n",
    "    # Fix spelling errors before prediction\n",
    "    textBlb = TextBlob(review)\n",
    "    corrected_review = textBlb.correct()\n",
    "\n",
    "    x_array = selector.transform(vectorizer.transform([corrected_review]))\n",
    "\n",
    "    return x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"I know a 5-star rating is potentially controversial for Tian Tian which has been a victim of its own success.  Before all the hullabaloo, before No Reservations, it was just a solid choice for chicken rice at Maxwell Food Centre.  And you know what? It continues to be a solid choice, delivering a solid consistently good, wholesome, flavorful, and traditionally authentic product.  So take away everything that's been written or said about Tian Tian in recent history and it'll stand on its own as a solid choice for chicken rice if you're in the neighborhood.  Is there a better chicken rice out there? Almost certainly, but that misses the entire point of a chicken rice stall in a food centre in Singapore.  At the end of the day, it's all about accessibility.  That these hawker centres were purpose-built to make affordable nutrition accessible.  That hawkers, over the years,  have devoted time and passion into making their offerings actually good is a wondrous unintended consequence of this most Singaporean of experiments.  So yes, Tian Tian is still good, pandemic or no, and hopefully will continue to be a solid go to option when wandering around Maxwell.  Do I think it's the best chicken rice in Singapore...for that answer you'll have to get to know me much better first.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I know a 5-star rating is potentially controversial for Tian Tian which has been a victim of its own success.  Before all the hullabaloo, before No Reservations, it was just a solid choice for chicken rice at Maxwell Food Centre.  And you know what? It continues to be a solid choice, delivering a solid consistently good, wholesome, flavorful, and traditionally authentic product.  So take away everything that's been written or said about Tian Tian in recent history and it'll stand on its own as a solid choice for chicken rice if you're in the neighborhood.  Is there a better chicken rice out there? Almost certainly, but that misses the entire point of a chicken rice stall in a food centre in Singapore.  At the end of the day, it's all about accessibility.  That these hawker centres were purpose-built to make affordable nutrition accessible.  That hawkers, over the years,  have devoted time and passion into making their offerings actually good is a wondrous unintended consequence of this most Singaporean of experiments.  So yes, Tian Tian is still good, pandemic or no, and hopefully will continue to be a solid go to option when wandering around Maxwell.  Do I think it's the best chicken rice in Singapore...for that answer you'll have to get to know me much better first.\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load(\"new_optimal_args/vectorizer.pkl\")\n",
    "selector = joblib.load(\"new_optimal_args/selector.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user = selector.transform(vectorizer.transform([review]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = joblib.load(\"new_optimal_args/final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = final_model.predict(x_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "   Welcome to the Suggested Star Rating System!\n",
      "\n",
      "            Copy and paste your review.\n",
      "\n",
      "       Type Control-D to exit the program.\n",
      "==================================================\n",
      "\n",
      "Enter review here: Imagine the smallest American town you can. Maybe a place where \"Make America Great\" signs are fading in front of every other mobile home.  Next, visualize the worst American-style Mexican you ever ate there. Maybe it was a place called Panchos. Maybe it was Senor Pedros. Who knows, it was bad. Maybe you went in, got some refried beans from a can with some instant rice, some tasteless generic salsa, a burrito that was 95% filler. And you remember being annoyed at wasting ten bucks.  Now, think of a restaurant that tastes literally two times worse, and costs $120 for two appetizers, three drinks, and one burrito. That would be the amazing restaurant that is Vatos in Singapore\n",
      "Your suggested star rating is: 1\n",
      "Thank you for using our Suggested Star Rating System!\n"
     ]
    }
   ],
   "source": [
    "run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rhedintzaaudryna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed initializing.\n",
      "(1, 0, 0.0001) Finished testing. | Accuracy:  0.8361052631578947\n",
      "(1, 0, 0.001) Finished testing. | Accuracy:  0.8345263157894737\n",
      "(1, 0, 0.01) Finished testing. | Accuracy:  0.7983947368421053\n",
      "(1, 0, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(1, 0, 1) Finished testing. | Accuracy:  0.7548157894736842\n",
      "(1, 10, 0.0001) Finished testing. | Accuracy:  0.8277894736842105\n",
      "(1, 10, 0.001) Finished testing. | Accuracy:  0.8330526315789474\n",
      "(1, 10, 0.01) Finished testing. | Accuracy:  0.7993421052631579\n",
      "(1, 10, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(1, 10, 1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(1, 20, 0.0001) Finished testing. | Accuracy:  0.8307105263157895\n",
      "(1, 20, 0.001) Finished testing. | Accuracy:  0.8326315789473684\n",
      "(1, 20, 0.01) Finished testing. | Accuracy:  0.7941578947368422\n",
      "(1, 20, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(1, 20, 1) Finished testing. | Accuracy:  0.7549736842105264\n",
      "(2, 0, 0.0001) Finished testing. | Accuracy:  0.822078947368421\n",
      "(2, 0, 0.001) Finished testing. | Accuracy:  0.8172631578947368\n",
      "(2, 0, 0.01) Finished testing. | Accuracy:  0.7853157894736842\n",
      "(2, 0, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(2, 0, 1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(2, 10, 0.0001) Finished testing. | Accuracy:  0.8184736842105264\n",
      "(2, 10, 0.001) Finished testing. | Accuracy:  0.8132894736842106\n",
      "(2, 10, 0.01) Finished testing. | Accuracy:  0.777578947368421\n",
      "(2, 10, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(2, 10, 1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(2, 20, 0.0001) Finished testing. | Accuracy:  0.8276315789473684\n",
      "(2, 20, 0.001) Finished testing. | Accuracy:  0.8140526315789474\n",
      "(2, 20, 0.01) Finished testing. | Accuracy:  0.7750789473684211\n",
      "(2, 20, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(2, 20, 1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(3, 0, 0.0001) Finished testing. | Accuracy:  0.8085789473684211\n",
      "(3, 0, 0.001) Finished testing. | Accuracy:  0.8032368421052631\n",
      "(3, 0, 0.01) Finished testing. | Accuracy:  0.7697368421052632\n",
      "(3, 0, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(3, 0, 1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(3, 10, 0.0001) Finished testing. | Accuracy:  0.8252631578947368\n",
      "(3, 10, 0.001) Finished testing. | Accuracy:  0.7970526315789473\n",
      "(3, 10, 0.01) Finished testing. | Accuracy:  0.7691052631578947\n",
      "(3, 10, 0.1) Finished testing. | Accuracy:  0.7546842105263158\n",
      "(3, 10, 1) Finished testing. | Accuracy:  0.7546842105263158\n"
     ]
    }
   ],
   "source": [
    "optimize_model(csv_file = \"test_data/merged_data.csv\", testing_fraction = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
